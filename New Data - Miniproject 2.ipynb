{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "092a6741",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f4e2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "import GPyOpt\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d743605b",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57dfc3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (20, 784) Test data shape: (10000, 784)\n",
      "Train labels shape: (20,)   Test labels shape: (10000,)\n",
      "Pool data shape: (1000, 784)   Pool labels shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# define number of classes\n",
    "train_pr_label = 2\n",
    "pool_size_pr_label = 100\n",
    "pool_size_pr_label += train_pr_label\n",
    "\n",
    "# load train and test sets\n",
    "train = pd.read_csv('Data/fashion-mnist_train.csv').to_numpy()\n",
    "test = pd.read_csv('Data/fashion-mnist_test.csv').to_numpy()\n",
    "\n",
    "X_train = train[:,1:]\n",
    "y_train = train[:,0]\n",
    "X_test = test[:,1:]\n",
    "y_test = test[:,0]\n",
    "\n",
    "where_train = []\n",
    "where_test = []\n",
    "where_pool = []\n",
    "\n",
    "for label in range(10):\n",
    "    where_train.append(np.where(y_train == label)[0][:train_pr_label])\n",
    "    where_test.append(np.where(y_test == label)[0])\n",
    "    where_pool.append(np.where(y_train == label)[0][train_pr_label:pool_size_pr_label])\n",
    "\n",
    "def flatten(array):\n",
    "    new_array = []\n",
    "    for sublist in array:\n",
    "        for item in sublist:\n",
    "            new_array.append(item)\n",
    "    return new_array\n",
    "    \n",
    "where_train = flatten(where_train)\n",
    "where_test = flatten(where_test)\n",
    "where_pool = flatten(where_pool)\n",
    "\n",
    "X_pool = X_train[where_pool]\n",
    "y_pool = y_train[where_pool]\n",
    "\n",
    "X_train = X_train[where_train]\n",
    "y_train = y_train[where_train]\n",
    "\n",
    "X_test = X_test[where_test]\n",
    "y_test = y_test[where_test]\n",
    "    \n",
    "print(\"Train data shape:\", X_train.shape, \"Test data shape:\", X_test.shape)\n",
    "print(\"Train labels shape:\", y_train.shape,\"  Test labels shape:\", y_test.shape)\n",
    "print(\"Pool data shape:\", X_pool.shape,\"  Pool labels shape:\", y_pool.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34e268d",
   "metadata": {},
   "source": [
    "# Naive Bayes Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a5747b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 10000 points : 3880\n",
      "38.800000000000004% mislabeled data.\n",
      "Mislabeled of class 0: 22.2\n",
      "Mislabeled of class 1: 8.3\n",
      "Mislabeled of class 2: 43.7\n",
      "Mislabeled of class 3: 32.7\n",
      "Mislabeled of class 4: 65.7\n",
      "Mislabeled of class 5: 76.0\n",
      "Mislabeled of class 6: 60.9\n",
      "Mislabeled of class 7: 13.700000000000001\n",
      "Mislabeled of class 8: 56.00000000000001\n",
      "Mislabeled of class 9: 8.799999999999999\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"% (X_test.shape[0], (y_test != y_pred).sum()))\n",
    "print(\"{0}% mislabeled data.\".format(((y_test != y_pred).sum()/X_test.shape[0])*100))\n",
    "\n",
    "mislabeled = [0,0,0,0,0,0,0,0,0,0]\n",
    "count = [0,0,0,0,0,0,0,0,0,0]\n",
    "for i in range(len(y_pred)):\n",
    "    count[int(y_test[i])] += 1\n",
    "    if y_pred[i] != y_test[i]:\n",
    "        mislabeled[int(y_test[i])] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Mislabeled of class {0}: {1}\".format(i,(mislabeled[i]/count[i])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab613f4d",
   "metadata": {},
   "source": [
    "# Loading Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41379207",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _loading:\n",
    "    \n",
    "    def __init__(self, count, headline):\n",
    "        self.count = count\n",
    "        self.current = 0\n",
    "        self.skip = 0\n",
    "        print(\"{0} in progress...\".format(headline))\n",
    "        \n",
    "    def _update(self):\n",
    "        self.current += 1\n",
    "        if self.current == self.count:\n",
    "            print(\"\\r{0}\".format(\"Finished Successfully!                               \\n\"))\n",
    "        elif self.skip > self.count/133:\n",
    "            print(\"\\r{0}\".format(\"|{0}{1}|   {2}% finished.\".format(\"â–ˆ\"*int(round(self.current/self.count,1)*20),\"-\"*(20-int(round(self.current/self.count,1)*20)),round((self.current/self.count)*100,2))), end = \"\", flush=True)\n",
    "            self.skip = 0\n",
    "            \n",
    "        else:\n",
    "            self.skip += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b6ae79",
   "metadata": {},
   "source": [
    "# Query By Comittee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "492f86c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in progress...\n"
     ]
    }
   ],
   "source": [
    "class QBC:\n",
    "    \n",
    "    model_number = 0\n",
    "    models = []\n",
    "    X_pool = []\n",
    "    y_pool = []\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    \n",
    "    compare_count = 0\n",
    "    compare_labels = {}\n",
    "    \n",
    "    loading_bar = _loading(0,\"\")\n",
    "    \n",
    "    def __init__(self,model_number,X_train,y_train,X_pool,y_pool,X_test,y_test):\n",
    "        \n",
    "        self.model_number = max(model_number,20)\n",
    "        self.initialize_models()\n",
    "        \n",
    "        self.X_pool = X_pool\n",
    "        self.y_pool = y_pool\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        \n",
    "        \n",
    "    def initialize_models(self):\n",
    "        params = [[\"newton-cg\",\"l2\"],[\"newton-cg\",\"none\"],[\"lbfgs\",\"l2\"],[\"lbfgs\",\"none\"],[\"liblinear\",\"l1\"],[\"liblinear\",\"l2\"],[\"sag\",\"l2\"],[\"sag\",\"none\"],[\"saga\",\"elasticnet\"],[\"saga\",\"l1\"]]\n",
    "        trees = np.arange(10,101,10)\n",
    "        \n",
    "        for i in range(int(np.floor(self.model_number/2))):\n",
    "            if params[i][1] == \"elasticnet\":\n",
    "                model = LogisticRegression(random_state=i, solver = params[i][0], penalty = params[i][1], l1_ratio=0.2)\n",
    "            else:\n",
    "                model = LogisticRegression(random_state=i, solver = params[i][0], penalty = params[i][1])\n",
    "            self.models.append(model)\n",
    "            \n",
    "        for i in range(int(np.floor(self.model_number/2))):\n",
    "            model = RandomForestClassifier(n_estimators = trees[i])\n",
    "            \n",
    "    def train_models(self):\n",
    "        for model in self.models:\n",
    "            model.fit(self.X_train,self.y_train)\n",
    "    \n",
    "    def acc_model(self):\n",
    "        scores = []\n",
    "        for model in self.models:\n",
    "            preds = model.predict(X_test)\n",
    "            scores.append(accuracy_score(preds,self.y_test))\n",
    "        \n",
    "        return np.mean(scores)\n",
    "            \n",
    "    \n",
    "    def find_pool_idx(self,heuristic):\n",
    "        y_preds = np.array([])\n",
    "        for model in self.models:\n",
    "            y_pred = model.predict(self.X_pool)\n",
    "            if len(y_preds) == 0:\n",
    "                y_preds = np.append(y_preds,y_pred)\n",
    "            else:\n",
    "                y_preds = np.vstack((y_preds,y_pred))\n",
    "                \n",
    "        if heuristic == \"majority\":\n",
    "            minimum = 11\n",
    "            pool_index = 0\n",
    "            for pred in range(len(y_preds[0])):\n",
    "                maks = 0\n",
    "                for label in range(10):\n",
    "                    count = np.count_nonzero(y_preds[:,pred] == label)\n",
    "                    if count > maks:\n",
    "                        maks = count\n",
    "                if maks < minimum:\n",
    "                    minimum = maks\n",
    "                    pool_index = pred\n",
    "                    \n",
    "        elif heuristic == \"vote_entropy\":\n",
    "            \n",
    "            values = []\n",
    "            for pred in range(len(y_preds[0])):\n",
    "                value = 0\n",
    "                for label in range(10):\n",
    "                    count = np.count_nonzero(y_preds[:,pred] == label)\n",
    "                    value += count/self.model_number*np.log(count/self.model_number) if count != 0 else 0\n",
    "                values.append(-value)\n",
    "            \n",
    "            pool_index = np.argmax(np.array(values))\n",
    "        \n",
    "        elif heuristic == \"random\":\n",
    "            pool_index = np.random.randint(len(self.X_pool))\n",
    "        \n",
    "        self.X_train = np.vstack((self.X_train,self.X_pool[pool_index]))\n",
    "        self.y_train = np.append(self.y_train,self.y_pool[pool_index])\n",
    "        \n",
    "        self.train_models()\n",
    "        \n",
    "        self.X_pool = np.delete(self.X_pool, pool_index, axis=0)\n",
    "        self.y_pool = np.delete(self.y_pool, pool_index, axis=0)\n",
    "        \n",
    "        return y_pool[pool_index]\n",
    "        \n",
    "    def query(self,itts,heuristics):\n",
    "        accs = []\n",
    "        labels = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
    "        for i in range(itts):\n",
    "            #print(f\"heuristic: {heuristics}, itt: {i} out of {itts}\")\n",
    "            label = self.find_pool_idx(heuristics)\n",
    "            accs.append(self.acc_model())\n",
    "            labels[label] += 1\n",
    "            self.loading_bar._update()\n",
    "        return accs, labels\n",
    "    \n",
    "    def compare_models(self,itts):\n",
    "        self.loading_bar = _loading(3*itts,\"Comparing QBC Models\")\n",
    "        \n",
    "        X_train_old = self.X_train\n",
    "        y_train_old = self.y_train\n",
    "        \n",
    "        self.train_models()\n",
    "        majority_accs, majority_labels = self.query(itts,\"majority\")\n",
    "        \n",
    "        self.X_train = X_train_old\n",
    "        self.y_train = y_train_old\n",
    "        self.train_models()\n",
    "        vote_entropy_accs, vote_entropy_labels = self.query(itts,\"vote_entropy\")\n",
    "        \n",
    "        \n",
    "        self.X_train = X_train_old\n",
    "        self.y_train = y_train_old\n",
    "        self.train_models()\n",
    "        random_accs, random_labels = self.query(itts,\"random\")\n",
    "        \n",
    "        self.plot_models([majority_accs,vote_entropy_accs,random_accs])\n",
    "        print(f\"Majority: {majority_labels}\")\n",
    "        print(f\"vote_entropy: {vote_entropy_labels}\")\n",
    "        print(f\"random: {random_labels}\")\n",
    "    \n",
    "        \n",
    "    def plot_models(self,accs):\n",
    "        \n",
    "        plt.plot(accs[0], label='majority')\n",
    "        plt.plot(accs[1], label='vote_entropy')\n",
    "        plt.plot(accs[2], label='random')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.legend(loc=\"upper left\")\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c988db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing QBC Models in progress...\n",
      "|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--------------|   25.13% finished."
     ]
    }
   ],
   "source": [
    "# Number of itterations (datapoints from pool) to sample.\n",
    "number_of_samples = 500\n",
    "# Number of models /// Number between 1-20.\n",
    "number_of_models = 20\n",
    "\n",
    "comittee = QBC(number_of_models,X_train,y_train,X_pool,y_pool,X_test,y_test)\n",
    "comittee.compare_models(number_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abbb1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971a28d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
