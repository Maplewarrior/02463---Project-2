{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "import GPyOpt\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into train, test and pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataPreprocessing(train_pr_label,test_pr_label,pool_size_pr_label,random_state):\n",
    "\n",
    "    pool_size_pr_label += train_pr_label\n",
    "\n",
    "    # load train and test sets\n",
    "    train = pd.read_csv('Data/fashion-mnist_train.csv').to_numpy()\n",
    "    test = pd.read_csv('Data/fashion-mnist_test.csv').to_numpy()\n",
    "\n",
    "    X_train = train[:,1:]\n",
    "    y_train = train[:,0]\n",
    "    X_test = test[:,1:]\n",
    "    y_test = test[:,0]\n",
    "\n",
    "    X_train, y_train = shuffle(X_train, y_train, random_state=random_state)\n",
    "    X_test, y_test = shuffle(X_test, y_test, random_state=random_state)\n",
    "\n",
    "    where_train = []\n",
    "    where_test = []\n",
    "    where_pool = []\n",
    "\n",
    "    for label in range(10):\n",
    "        where_train.append(np.where(y_train == label)[0][:train_pr_label])\n",
    "        where_test.append(np.where(y_test == label)[0][:test_pr_label])\n",
    "        where_pool.append(np.where(y_train == label)[0][train_pr_label:pool_size_pr_label])\n",
    "\n",
    "    def flatten(array):\n",
    "        new_array = []\n",
    "        for sublist in array:\n",
    "            for item in sublist:\n",
    "                new_array.append(item)\n",
    "        return new_array\n",
    "        \n",
    "    where_train = flatten(where_train)\n",
    "    where_test = flatten(where_test)\n",
    "    where_pool = flatten(where_pool)\n",
    "\n",
    "    X_pool = X_train[where_pool]\n",
    "    y_pool = y_train[where_pool]\n",
    "\n",
    "    X_train = X_train[where_train]\n",
    "    y_train = y_train[where_train]\n",
    "\n",
    "    X_test = X_test[where_test]\n",
    "    y_test = y_test[where_test]\n",
    "        \n",
    "    print(\"Train data shape:\", X_train.shape, \"Test data shape:\", X_test.shape)\n",
    "    print(\"Train labels shape:\", y_train.shape,\"  Test labels shape:\", y_test.shape)\n",
    "    print(\"Pool data shape:\", X_pool.shape,\"  Pool labels shape:\", y_pool.shape)\n",
    "    \n",
    "    print(f\"{np.count_nonzero(X_pool == label)}\")\n",
    "    \n",
    "    return X_train,y_train,X_test,y_test,X_pool,y_pool\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative data split for making class imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (2500, 784) Test data shape: (1000, 784)\n",
      "Train labels shape: (2500,)   Test labels shape: (1000,)\n",
      "Pool data shape: (1000, 784)   Pool labels shape: (1000,)\n",
      "Class distribution, pool:\n",
      "Class 0 100\n",
      "Class 1 100\n",
      "Class 2 100\n",
      "Class 3 100\n",
      "Class 4 100\n",
      "Class 5 100\n",
      "Class 6 100\n",
      "Class 7 100\n",
      "Class 8 100\n",
      "Class 9 100\n",
      "Class distribution train\n",
      "Class 0 250\n",
      "Class 1 250\n",
      "Class 2 250\n",
      "Class 3 250\n",
      "Class 4 250\n",
      "Class 5 250\n",
      "Class 6 250\n",
      "Class 7 250\n",
      "Class 8 250\n",
      "Class 9 250\n",
      "(2500, 784)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# define number of classes\n",
    "begining_index = 0\n",
    "n_classes = 10\n",
    "#train_class_sizes = [15,15,15,15,15,5,5,5,5,5]\n",
    "train_class_sizes = [250 for _ in range(10)]\n",
    "#test_class_sizes =  [50,50,50,50,50,50,50,50,50,50]\n",
    "test_class_sizes = [100 for _ in range(10)]\n",
    "pool_size = 100\n",
    "# load train and test sets\n",
    "train = pd.read_csv('Data/fashion-mnist_train.csv').to_numpy()\n",
    "test = pd.read_csv('Data/fashion-mnist_test.csv').to_numpy()\n",
    "\n",
    "X_train = train[:,1:]\n",
    "y_train = train[:,0]\n",
    "X_test = test[:,1:]\n",
    "y_test = test[:,0]\n",
    "\n",
    "where_train = []\n",
    "where_test = []\n",
    "where_pool = []\n",
    "\n",
    "for label in range(begining_index,begining_index+n_classes):\n",
    "    where_train.append(np.where(y_train == label)[0][:train_class_sizes[label]])\n",
    "    where_test.append(np.where(y_test == label)[0][:test_class_sizes[label]])\n",
    "    where_pool.append(np.where(y_train == label)[0][train_class_sizes[label]:pool_size+train_class_sizes[label]])\n",
    "\n",
    "def flatten(array):\n",
    "    new_array = []\n",
    "    for sublist in array:\n",
    "        for item in sublist:\n",
    "            new_array.append(item)\n",
    "    return new_array\n",
    "    \n",
    "where_train = flatten(where_train)\n",
    "where_test = flatten(where_test)\n",
    "where_pool = flatten(where_pool)\n",
    "\n",
    "X_pool = X_train[where_pool]\n",
    "y_pool = y_train[where_pool]\n",
    "\n",
    "X_train = X_train[where_train]\n",
    "y_train = y_train[where_train]\n",
    "\n",
    "X_test = X_test[where_test]\n",
    "y_test = y_test[where_test]\n",
    "    \n",
    "print(\"Train data shape:\", X_train.shape, \"Test data shape:\", X_test.shape)\n",
    "print(\"Train labels shape:\", y_train.shape,\"  Test labels shape:\", y_test.shape)\n",
    "print(\"Pool data shape:\", X_pool.shape,\"  Pool labels shape:\", y_pool.shape)\n",
    "\n",
    "print(\"Class distribution, pool:\")\n",
    "for i in range(10):\n",
    "    print(\"Class\", i, np.count_nonzero(y_pool == i))\n",
    "print(\"Class distribution train\")\n",
    "for i in range(10):\n",
    "    print(\"Class\", i, np.count_nonzero(y_train == i))\n",
    "\n",
    "\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading bar :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _loading:\n",
    "    \n",
    "    def __init__(self, count, headline):\n",
    "        self.count = count\n",
    "        self.current = 0\n",
    "        self.skip = 0\n",
    "        print(\"\\n{0} in progress...\".format(headline))\n",
    "        \n",
    "    def _update(self):\n",
    "        self.current += 1\n",
    "        if self.current == self.count:\n",
    "            print(\"\\r{0}\".format(\"Finished Successfully!                               \\n\"))\n",
    "        elif self.skip > self.count/133:\n",
    "            print(\"\\r{0}\".format(\"|{0}{1}|   {2}% finished.\".format(\"â–ˆ\"*int(round(self.current/self.count,1)*20),\"-\"*(20-int(round(self.current/self.count,1)*20)),round((self.current/self.count)*100,2))), end = \"\", flush=True)\n",
    "            self.skip = 0\n",
    "            \n",
    "        else:\n",
    "            self.skip += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " in progress...\n"
     ]
    }
   ],
   "source": [
    "class Sampler:\n",
    "    \n",
    "    model_number = 0\n",
    "    models = []\n",
    "    X_pool = []\n",
    "    y_pool = []\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    X_train_old = []\n",
    "    y_train_old = []\n",
    "    \n",
    "    compare_count = 0\n",
    "    compare_labels = {}\n",
    "    \n",
    "    loading_bar = _loading(0,\"\")\n",
    "    \n",
    "    def __init__(self,model_number,X_train,y_train,X_pool,y_pool,X_test,y_test):\n",
    "        \n",
    "        self.model_number = max(model_number,20)\n",
    "        \n",
    "        self.X_pool = X_pool\n",
    "        self.y_pool = y_pool\n",
    "        self.X_pool_old = X_pool\n",
    "        self.y_pool_old = y_pool\n",
    "        \n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_train_old = X_train\n",
    "        self.y_train_old = y_train\n",
    "        \n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.n_classes = len(np.unique(y_test))\n",
    "        \n",
    "        self.lr = LogisticRegression(penalty='l2', C=1.)\n",
    "        self.initialize_models()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def shuffle_data(self):\n",
    "        zip_list = list(zip(self.X_pool, self.y_pool))\n",
    "        random.shuffle(zip_list)\n",
    "        self.X_pool, self.y_pool = zip(*zip_list)\n",
    "        \n",
    "        \n",
    "    def initialize_models(self):\n",
    "        params = [[\"newton-cg\",\"l2\"],[\"newton-cg\",\"none\"],[\"lbfgs\",\"l2\"],[\"lbfgs\",\"none\"],[\"liblinear\",\"l1\"],[\"liblinear\",\"l2\"],[\"sag\",\"l2\"],[\"sag\",\"none\"],[\"saga\",\"elasticnet\"],[\"saga\",\"l1\"]]\n",
    "        trees = np.arange(200,301,10)\n",
    "        \n",
    "        for i in range(int(np.floor(self.model_number/2))):\n",
    "            if params[i][1] == \"elasticnet\":\n",
    "                model = LogisticRegression(random_state=i, solver = params[i][0], penalty = params[i][1], l1_ratio=0.2)\n",
    "            else:\n",
    "                model = LogisticRegression(random_state=i, solver = params[i][0], penalty = params[i][1])\n",
    "            self.models.append(model)\n",
    "            \n",
    "        for i in range(int(np.floor(self.model_number/2))):\n",
    "            model = RandomForestClassifier(n_estimators = trees[i])\n",
    "            self.models.append(model)\n",
    "\n",
    "        self.train_models()\n",
    "    def train_models(self):\n",
    "        self.train_final_model()\n",
    "        for model in self.models:\n",
    "            model.fit(self.X_train, self.y_train)\n",
    "            \n",
    "    \n",
    "    def train_final_model(self):\n",
    "        #for model in self.models:\n",
    "        #    model.fit(self.X_train,self.y_train)\n",
    "        # train only the logistic regression model with newton-cg and l2\n",
    "        self.lr.fit(self.X_train,self.y_train)\n",
    "    \n",
    "    def reset_models(self):\n",
    "        self.X_train = np.copy(self.X_train_old)\n",
    "        self.y_train = np.copy(self.y_train_old)\n",
    "        self.train_models()\n",
    "        self.X_pool = np.copy(self.X_pool_old)\n",
    "        self.y_pool = np.copy(self.y_pool_old)\n",
    "        \n",
    "\n",
    "    def acc_model(self):\n",
    "        # = []\n",
    "        #for model in self.models:\n",
    "        #    preds = model.predict(X_test)\n",
    "        #    scores.append(accuracy_score(preds,self.y_test))\n",
    "        #preds = self.models[0].predict(self.X_test)\n",
    "        \n",
    "        preds = self.lr.predict(self.X_test)\n",
    "        score = accuracy_score(self.y_test, preds)\n",
    "        return score\n",
    "            \n",
    "    \n",
    "    def find_pool_idx(self,heuristic):\n",
    "        y_preds = np.array([])\n",
    "        if heuristic in [\"qbc_majority, qbc_vote_entropy\",\"random\"]:\n",
    "            for model in self.models:\n",
    "                y_pred = model.predict(self.X_pool)\n",
    "                if len(y_preds) == 0:\n",
    "                    y_preds = np.append(y_preds,y_pred)\n",
    "                else:\n",
    "                    y_preds = np.vstack((y_preds,y_pred))\n",
    "        else:\n",
    "            model = self.models[0]\n",
    "            y_preds = model.predict_proba(self.X_pool)\n",
    "\n",
    "        if heuristic == \"qbc_majority\":\n",
    "            minimum = 10000\n",
    "            pool_index = 0\n",
    "            for pred in range(len(y_preds[0])):\n",
    "                maks = 0\n",
    "                for label in range(self.n_classes):\n",
    "                    count = np.count_nonzero(y_preds[:,pred] == label)\n",
    "                    #count2 = len(y_preds[y_preds == ])\n",
    "                    if count > maks:\n",
    "                        maks = count\n",
    "                if maks < minimum:\n",
    "                    minimum = maks\n",
    "                    pool_index = pred     \n",
    "                    \n",
    "        elif heuristic == \"qbc_vote_entropy\":\n",
    "            values = []\n",
    "            for pred in range(len(y_preds[0])):\n",
    "                value = 0\n",
    "                for label in range(self.n_classes):\n",
    "                    count = np.count_nonzero(y_preds[:,pred] == label)\n",
    "                    value += count/self.model_number*np.log(count/self.model_number) if count != 0 else 0\n",
    "                values.append(-value)\n",
    "            \n",
    "            pool_index = np.argmax(np.array(values))\n",
    "            \n",
    "        elif heuristic == \"random\":\n",
    "            pool_index = np.random.randint(len(self.y_pool))\n",
    "            # print(self.y_pool[self.y_pool==8])\n",
    "            # print(self.y_pool[self.y_pool==9])\n",
    "            \n",
    "            \n",
    "        elif heuristic == \"uncertainty_lc\":\n",
    "            pool_index = np.argsort(-y_preds.max(1))[-1]\n",
    "            \n",
    "        elif heuristic == \"uncertainty_entropy\":\n",
    "            pool_index = np.argmax(-np.sum(y_preds*np.log(y_preds), axis = 0))\n",
    "        \n",
    "        self.X_train = np.vstack((self.X_train,self.X_pool[pool_index]))\n",
    "        self.y_train = np.append(self.y_train,self.y_pool[pool_index])\n",
    "        \n",
    "        self.train_final_model()\n",
    "        \n",
    "        val = self.y_pool[pool_index]\n",
    "        self.X_pool = np.delete(self.X_pool, pool_index, axis=0)\n",
    "        self.y_pool = np.delete(self.y_pool, pool_index, axis=0)\n",
    "        \n",
    "        return val\n",
    "        \n",
    "    def query(self,itts,heuristics):\n",
    "        self.reset_models()\n",
    "        self.shuffle_data()\n",
    "        \n",
    "        \n",
    "        accs = []\n",
    "        accs.append(self.acc_model())\n",
    "        #labels = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
    "        #labels = {0:0, 1:0, 2:0}\n",
    "        labels = {j:0 for j in range(self.n_classes)}\n",
    "        for i in range(itts):\n",
    "            #print(f\"heuristic: {heuristics}, itt: {i} out of {itts}\")\n",
    "            label = self.find_pool_idx(heuristics)\n",
    "            accs.append(self.acc_model())\n",
    "            labels[label] += 1\n",
    "            self.loading_bar._update()\n",
    "        return accs, labels\n",
    "    \n",
    "    def compare_models(self,itts,compare_itt,repeats):\n",
    "        self.loading_bar = _loading(5*itts,f\"Comparing QBC Models // Repetition {compare_itt} out of {repeats}\")\n",
    "        \n",
    "        # query by committee\n",
    "        majority_accs, majority_labels = self.query(itts,\"qbc_majority\")\n",
    "        vote_entropy_accs, vote_entropy_labels = self.query(itts,\"qbc_vote_entropy\")\n",
    "        # uncertainty sampling with least confident\n",
    "        uncertainty_lc_accs, uncertainty_lc_labels = self.query(itts,\"uncertainty_lc\")\n",
    "        uncertainty_entropy_accs, uncertainty_entropy_labels = self.query(itts,\"uncertainty_entropy\")\n",
    "        random_accs, random_labels = self.query(itts,\"random\")\n",
    "\n",
    "        print(f\"\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ Repetition {compare_itt} ////////////////\")\n",
    "\n",
    "        print(f\"Majority Voting Samples: {majority_labels}\")\n",
    "        print(f\"Vote Entropy Samples: {vote_entropy_labels}\")\n",
    "        print(f\"Uncertainty sampling with LC: {uncertainty_lc_labels}\")\n",
    "        print(f\"Uncertainty sampling with entropy: {uncertainty_entropy_labels}\")\n",
    "        print(f\"Random Samples: {random_labels}\")\n",
    "\n",
    "        print(f\"Majority Voting Accuracy: {majority_accs[-1]}\")\n",
    "        print(f\"Vote Entropy Accuracy: {vote_entropy_accs[-1]}\")\n",
    "        print(f\"Uncertainty sampling with LC: {uncertainty_lc_accs[-1]}\")\n",
    "        print(f\"Uncertainty sampling with entropy: {uncertainty_entropy_accs[-1]}\")\n",
    "        print(f\"Random Accuracy: {random_accs[-1]}\\n\")\n",
    "        \n",
    "        self.plot_models([majority_accs,\n",
    "                          vote_entropy_accs,\n",
    "                          uncertainty_lc_accs,\n",
    "                          uncertainty_entropy_accs,\n",
    "                          random_accs],compare_itt,repeats)\n",
    "    \n",
    "    def compare_models_repeat(self, itts, repeats):\n",
    "        for rep in range(repeats):\n",
    "            self.compare_models(itts,rep+1,repeats)\n",
    "\n",
    "    def plot_models(self,accs,compare_itt,repeats):\n",
    "        \n",
    "        if compare_itt == repeats:\n",
    "            plt.plot(accs[0], label='Majority Voting', color = \"red\")\n",
    "            plt.plot(accs[1], label='Vote Entropy', color = \"blue\")\n",
    "            plt.plot(accs[2], label='Uncertainty LC', color = \"orange\")\n",
    "            plt.plot(accs[3], label='Uncertainty entropy', color = \"purple\")\n",
    "            plt.plot(accs[4], label='Random', color = \"green\")\n",
    "            plt.ylabel('accuracy')\n",
    "            plt.xlabel(\"Pool Samples\")\n",
    "            plt.legend(loc=\"upper left\")\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.plot(accs[0], color = \"red\")\n",
    "            plt.plot(accs[1], color = \"blue\")\n",
    "            plt.plot(accs[2], color = \"orange\")\n",
    "            plt.plot(accs[3], color = \"purple\")\n",
    "            plt.plot(accs[4], color = \"green\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "Class 0 250\n",
      "Class 1 250\n",
      "Class 2 250\n",
      "Class 3 250\n",
      "Class 4 250\n",
      "Class 5 250\n",
      "Class 6 250\n",
      "Class 7 250\n",
      "Class 8 250\n",
      "Class 9 250\n",
      "Class 0 100\n",
      "Class 1 100\n",
      "Class 2 100\n",
      "Class 3 100\n",
      "Class 4 100\n",
      "Class 5 100\n",
      "Class 6 100\n",
      "Class 7 100\n",
      "Class 8 100\n",
      "Class 9 100\n",
      "Class 0 100\n",
      "Class 1 100\n",
      "Class 2 100\n",
      "Class 3 100\n",
      "Class 4 100\n",
      "Class 5 100\n",
      "Class 6 100\n",
      "Class 7 100\n",
      "Class 8 100\n",
      "Class 9 100\n",
      "\n",
      "Comparing QBC Models // Repetition 1 out of 1 in progress...\n",
      "|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------|   52.0% finished.."
     ]
    }
   ],
   "source": [
    "# Number of itterations (datapoints from pool) to sample.\n",
    "number_of_samples = 60\n",
    "# Number of models /// Number between 1-20.\n",
    "number_of_models = 20\n",
    "# Number of repeats of comparison.\n",
    "number_of_repeats = 1\n",
    "\n",
    "train_pr_label = 84\n",
    "test_pr_label = 500\n",
    "pool_size_pr_label = 100\n",
    "random_state = 10\n",
    "\n",
    "\n",
    "#X_train,y_train,X_test,y_test,X_pool,y_pool = DataPreprocessing(train_pr_label,test_pr_label,pool_size_pr_label,random_state)\n",
    "\n",
    "print(\"Class distribution:\")\n",
    "for i in range(10):\n",
    "    print(\"Class\", i, np.count_nonzero(y_train == i))\n",
    "    \n",
    "for i in range(10):\n",
    "    print(\"Class\", i, np.count_nonzero(y_pool == i))\n",
    "    \n",
    "for i in range(10):\n",
    "    print(\"Class\", i, np.count_nonzero(y_test == i))\n",
    "\n",
    "committee = Sampler(number_of_models,X_train,y_train,X_pool,y_pool,X_test,y_test)\n",
    "committee.compare_models_repeat(number_of_samples, number_of_repeats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.savefig(\"d.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
